# Aprendendo Pyspark <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/2560px-Apache_Spark_logo.svg.png"  width="60" height="30">
Estarei utilizando este repositório para registrar o meu avanço no curso do Fernando Amaral disponível no link abaixo.
Bem como guardar a resolução das atividades realizadas durante o curso.

https://www.udemy.com/course/spark-curso-completo/

## Ambiente

O ambiente indicado pelo instrutor foi uma máquina virtual Linux Ubuntu. Para criá-la e acessá-la diretamente utilizei o Virtual Box e o Putty para acelerar o acesso via SSH.

<img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/vm.png"  width="60" height="60"> <img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/ubuntu.png"  width="100" height="60"> <img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/putty.png"  width="60" height="60">

Durante o desenvolvimento do curso também foram utilizados os bancos Postgres e Mongodb, além de Notebooks Jupyter com Python.

<img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/mongodb.png"  width="60" height="60"> <img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/postgres.png"  width="60" height="60"> <img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/jupyter.png"  width="60" height="60"> <img src="https://github.com/wesleyssantos27/pyspark_studies/blob/main/img/icons/python.webp"  width="60" height="60">



## Conteúdo
O curso aborda os seguintes tópicos:

- Aprender a instalar e configurar o Spark
- Conhecer o principal objeto de dados: DataFrames do Spark
- Processar DataFrames através de transformações e ações
- Consultar Dados no Spark com Sintaxe SQL
- Criar Views e fazer Joins
- Persistir dados em disco, criando tabelas em formatos como Parquet e ORC
- Importar dados de fontes como Mongodb, PostgreSQL e arquivos como Json e Parquet
- Criar aplicações que você pode rodar na linha de comendo
- Machine Learning com Spark: criação modelos e realização de previsões
- Construção de Pipelines de Marchine Learning
- Processamento dados em tempo real com Spark Structured Streaming
- Otimização do Spark com Cache, Persistência, Particionamento e Bucketing
- Uso do Spark com Jupyter Notebooks
- Uso do Spark com Pandas e outras bibliotecas do Python
- Construção de um Cluster

## Atividades

Abaixo listei a resolução de todas as atividades feitas por mim e aprimoradas à partir das resoluções do professor:

- [Atividade 1](https://github.com/wesleyssantos27/pyspark_studies/blob/main/Atividades/Atividade1.md)
- [Atividade 2](https://github.com/wesleyssantos27/pyspark_studies/blob/main/Atividades/Atividade2.md)
- [Atividade 3](https://github.com/wesleyssantos27/pyspark_studies/blob/main/Atividades/Atividade3.md)
